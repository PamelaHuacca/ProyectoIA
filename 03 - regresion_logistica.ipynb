{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luiscontreras7/Proyecto-IA-1-/blob/main/03_Regresion_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V_6E9p8HDkz",
        "outputId": "d834e177-1ab1-490d-97a2-a7aa2788f0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "usage: kaggle [-h] [-v] [-W]\n",
            "              {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
            "              ...\n",
            "kaggle: error: the following arguments are required: command\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "!kaggle\n",
        "!chmod 600 ./kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QIDOttuG5Pf",
        "outputId": "c85e6827-cb48-49fb-fdb6-8f0097031852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 1.11GB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJncLJDLItzC",
        "outputId": "57ce874b-a034-4ffd-a13b-87c5eb145bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip\n",
            "  inflating: submission_example.csv  \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13vGDyTwKfML"
      },
      "source": [
        "El paradigma a seguir es supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYWLjVXWTczE",
        "outputId": "2bc15ced-17be-4a3a-ff13-8c43183af92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "Ef4GgbrOT3WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufFLXC9lxN1z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def cargar_datos_preprocesados():\n",
        "        df = pd.read_csv('train.csv')  # O el archivo que tengas\n",
        "        print(f\"Datos cargados: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "# Cargar datos\n",
        "df = cargar_datos_preprocesados()\n",
        "TARGET_COL = 'RENDIMIENTO_GLOBAL'\n",
        "ID_COL = 'ID'\n",
        "\n",
        "print(f\"Columnas en el dataset: {list(df.columns)}\")\n",
        "print(f\"Tipos de datos originales:\")\n",
        "print(df.dtypes.value_counts())\n",
        "if TARGET_COL in df.columns:\n",
        "    print(f\"\\nDistribución de la variable objetivo ({TARGET_COL}):\")\n",
        "    target_counts = df[TARGET_COL].value_counts().sort_index()\n",
        "    print(target_counts)\n",
        "\n",
        "    # Visualizar distribución del target\n",
        "    fig = px.bar(x=target_counts.index, y=target_counts.values,\n",
        "                 title=f'Distribución de la Variable Objetivo: {TARGET_COL}',\n",
        "                 labels={'x': TARGET_COL, 'y': 'Frecuencia'},\n",
        "                 color=target_counts.values,\n",
        "                 color_continuous_scale='viridis')\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBppRX1A2Lb3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ===================================================================\n",
        "# IDENTIFICAR TIPOS DE COLUMNAS PARA CONVERSIÓN\n",
        "# ===================================================================\n",
        "\n",
        "def identificar_columnas_para_conversion(df, target_col='RENDIMIENTO_GLOBAL', id_col='ID'):\n",
        "    \"\"\"\n",
        "    Identifica qué tipo de conversión necesita cada columna.\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== IDENTIFICANDO TIPOS DE COLUMNAS PARA CONVERSIÓN ===\")\n",
        "\n",
        "    # Columnas a excluir\n",
        "    excluir = [target_col, id_col] if id_col in df.columns else [target_col]\n",
        "\n",
        "    tipos_conversion = {\n",
        "        'numericas': [],           # Ya están en formato correcto\n",
        "        'ordinales': [],           # Necesitan LabelEncoder con orden específico\n",
        "        'binarias': [],           # Necesitan mapeo simple 0/1\n",
        "        'nominales_pocas': [],    # OneHotEncoder (≤ 10 categorías)\n",
        "        'nominales_muchas': [],   # LabelEncoder simple (> 10 categorías)\n",
        "        'texto': [],              # TF-IDF o CountVectorizer\n",
        "        'excluir': excluir        # No procesar\n",
        "    }\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in excluir:\n",
        "            continue\n",
        "\n",
        "        # Si ya es numérica, mantener\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            tipos_conversion['numericas'].append(col)\n",
        "            continue\n",
        "\n",
        "        # Contar valores únicos\n",
        "        valores_unicos = df[col].nunique()\n",
        "        muestra_valores = df[col].dropna().unique()[:5]  # Primeros 5 valores para inspección\n",
        "\n",
        "        print(f\"\\nColumna: {col}\")\n",
        "        print(f\"  Valores únicos: {valores_unicos}\")\n",
        "        print(f\"  Muestra: {muestra_valores}\")\n",
        "\n",
        "        # Decidir tipo de conversión\n",
        "        if valores_unicos == 2:\n",
        "            tipos_conversion['binarias'].append(col)\n",
        "            print(f\"  → BINARIA\")\n",
        "\n",
        "        elif any(keyword in ' '.join(str(v).lower() for v in muestra_valores)\n",
        "                for keyword in ['estrato', 'primaria', 'bachillerato', 'universitaria', 'postgrado', 'bajo', 'medio', 'alto']):\n",
        "            tipos_conversion['ordinales'].append(col)\n",
        "            print(f\"  → ORDINAL\")\n",
        "\n",
        "        elif valores_unicos <= 10:\n",
        "            tipos_conversion['nominales_pocas'].append(col)\n",
        "            print(f\"  → NOMINAL (OneHot)\")\n",
        "\n",
        "        elif valores_unicos <= 50:\n",
        "            tipos_conversion['nominales_muchas'].append(col)\n",
        "            print(f\"  → NOMINAL (Label)\")\n",
        "\n",
        "        else:\n",
        "            tipos_conversion['texto'].append(col)\n",
        "            print(f\"  → TEXTO (TF-IDF)\")\n",
        "\n",
        "    return tipos_conversion\n",
        "\n",
        "tipos_conversion = identificar_columnas_para_conversion(df)\n",
        "\n",
        "# Mostrar resumen\n",
        "print(f\"\\n=== RESUMEN DE CONVERSIONES A REALIZAR ===\")\n",
        "for tipo, columnas in tipos_conversion.items():\n",
        "    if columnas:\n",
        "        print(f\"{tipo.upper()}: {len(columnas)} columnas\")\n",
        "        print(f\"  {columnas}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-dRy2cc2Zhv"
      },
      "outputs": [],
      "source": [
        "# ===================================================================\n",
        "# FUNCIONES DE CONVERSIÓN ESPECÍFICAS\n",
        "# ===================================================================\n",
        "\n",
        "def convertir_binarias(df, columnas_binarias):\n",
        "    \"\"\"\n",
        "    Convierte columnas con valores 'Si'/'No' o 'S'/'N' a 1 y 0 respectivamente.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Convirtiendo columnas binarias (Si/No y S/N) ---\")\n",
        "    df_resultado = df.copy()\n",
        "    mapeos_binarios = {}\n",
        "\n",
        "    for col in columnas_binarias:\n",
        "        valores_unicos = df[col].dropna().unique()\n",
        "        print(f\"Columna: {col}\")\n",
        "        print(f\"  Valores únicos: {valores_unicos}\")\n",
        "\n",
        "        if set(valores_unicos) == {\"Si\", \"No\"} or set(valores_unicos) == {\"S\", \"N\"}:\n",
        "            if \"Si\" in valores_unicos:\n",
        "                mapeo = {\"No\": 0, \"Si\": 1}\n",
        "            else:\n",
        "                mapeo = {\"N\": 0, \"S\": 1}\n",
        "            df_resultado[col] = df[col].map(mapeo)\n",
        "            mapeos_binarios[col] = mapeo\n",
        "            print(f\"  → Mapeo aplicado: {mapeo}\")\n",
        "        else:\n",
        "            print(f\"  ERROR: {col} no contiene exactamente los valores esperados ('Si/No' o 'S/N')\")\n",
        "\n",
        "    return df_resultado, mapeos_binarios\n",
        "\n",
        "def convertir_ordinales(df, columnas_ordinales):\n",
        "    \"\"\"\n",
        "    Convierte columnas ordinales respetando el orden.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Convirtiendo columnas ordinales ---\")\n",
        "    df_resultado = df.copy()\n",
        "    mapeos_ordinales = {}\n",
        "\n",
        "    # Órdenes predefinidos para columnas comunes\n",
        "    ordenes_conocidos = {\n",
        "        'estrato_limpio': ['estrato 1', 'estrato 2', 'estrato 3', 'estrato 4', 'estrato 5', 'estrato 6'],\n",
        "        'edu_padre_limpio': ['primaria incompleta', 'primaria completa', 'bachillerato', 'tecnica', 'universitaria', 'postgrado'],\n",
        "        'edu_madre_limpio': ['primaria incompleta', 'primaria completa', 'bachillerato', 'tecnica', 'universitaria', 'postgrado'],\n",
        "        'RENDIMIENTO_GLOBAL': ['bajo', 'medio-bajo', 'medio-alto', 'alto'],\n",
        "        'horas_trabajo_limpio': ['no trabaja', '1-10 horas', '11-20 horas', '21-30 horas', 'mas de 30']\n",
        "    }\n",
        "\n",
        "    for col in columnas_ordinales:\n",
        "        # Usar orden conocido si existe, sino orden alfabético\n",
        "        if col in ordenes_conocidos:\n",
        "            orden = ordenes_conocidos[col]\n",
        "        else:\n",
        "            # Detectar orden automáticamente o usar alfabético\n",
        "            valores_unicos = sorted(df[col].dropna().unique())\n",
        "            orden = valores_unicos\n",
        "            print(f\"  ADVERTENCIA: {col} no tiene orden predefinido, usando alfabético: {orden}\")\n",
        "\n",
        "        # Crear mapeo ordinal\n",
        "        mapeo = {valor: i for i, valor in enumerate(orden)}\n",
        "\n",
        "        # Aplicar mapeo\n",
        "        df_resultado[col] = df[col].map(mapeo)\n",
        "        mapeos_ordinales[col] = mapeo\n",
        "\n",
        "        print(f\"  {col}: {mapeo}\")\n",
        "\n",
        "    return df_resultado, mapeos_ordinales\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9q_IOnJ2d2O"
      },
      "outputs": [],
      "source": [
        "def convertir_nominales_onehot(df, columnas_nominales):\n",
        "    \"\"\"\n",
        "    Convierte columnas nominales usando OneHot encoding.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Convirtiendo columnas nominales (OneHot) ---\")\n",
        "    df_resultado = df.copy()\n",
        "    mapeos_onehot = {}\n",
        "\n",
        "    for col in columnas_nominales:\n",
        "        # Crear variables dummy\n",
        "        dummies = pd.get_dummies(df[col], prefix=col, dummy_na=True)\n",
        "\n",
        "        # Agregar al dataframe\n",
        "        df_resultado = pd.concat([df_resultado, dummies], axis=1)\n",
        "\n",
        "        # Eliminar columna original\n",
        "        df_resultado = df_resultado.drop(columns=[col])\n",
        "\n",
        "        # Guardar mapeo\n",
        "        categorias = df[col].unique()\n",
        "        mapeos_onehot[col] = {\n",
        "            'categorias': categorias,\n",
        "            'columnas_generadas': list(dummies.columns)\n",
        "        }\n",
        "\n",
        "        print(f\"  {col}: {len(dummies.columns)} columnas generadas\")\n",
        "        print(f\"    {list(dummies.columns)[:3]}...\" if len(dummies.columns) > 3 else f\"    {list(dummies.columns)}\")\n",
        "\n",
        "    return df_resultado, mapeos_onehot\n",
        "\n",
        "def convertir_nominales_label(df, columnas_nominales):\n",
        "    \"\"\"\n",
        "    Convierte columnas nominales usando Label encoding.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Convirtiendo columnas nominales (Label) ---\")\n",
        "    df_resultado = df.copy()\n",
        "    mapeos_label = {}\n",
        "\n",
        "    for col in columnas_nominales:\n",
        "        le = LabelEncoder()\n",
        "\n",
        "        # Manejar valores NaN\n",
        "        valores_no_na = df[col].dropna()\n",
        "        if len(valores_no_na) > 0:\n",
        "            le.fit(valores_no_na)\n",
        "\n",
        "            # Aplicar encoding\n",
        "            df_resultado[col] = df[col].apply(lambda x: le.transform([x])[0] if pd.notna(x) else -1)\n",
        "\n",
        "            # Guardar mapeo\n",
        "            mapeos_label[col] = {\n",
        "                'encoder': le,\n",
        "                'mapeo': dict(zip(le.classes_, le.transform(le.classes_))),\n",
        "                'valor_na': -1\n",
        "            }\n",
        "\n",
        "            print(f\"  {col}: {len(le.classes_)} categorías únicas\")\n",
        "            print(f\"    Muestra: {dict(list(mapeos_label[col]['mapeo'].items())[:3])}\")\n",
        "        else:\n",
        "            print(f\"  ERROR: {col} no tiene valores válidos\")\n",
        "\n",
        "    return df_resultado, mapeos_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfAWEqwy2gbY"
      },
      "outputs": [],
      "source": [
        "def convertir_texto_tfidf(df, columnas_texto, max_features=50):\n",
        "    \"\"\"\n",
        "    Convierte columnas de texto usando TF-IDF.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Convirtiendo columnas de texto (TF-IDF) ---\")\n",
        "    df_resultado = df.copy()\n",
        "    mapeos_texto = {}\n",
        "\n",
        "    for col in columnas_texto:\n",
        "        # Preparar datos de texto\n",
        "        textos = df[col].fillna('').astype(str)\n",
        "\n",
        "        # Crear TF-IDF vectorizer\n",
        "        tfidf = TfidfVectorizer(\n",
        "            max_features=max_features,\n",
        "            lowercase=True,\n",
        "            stop_words=None,  # No eliminar stop words para programas académicos\n",
        "            ngram_range=(1, 2),  # Unigramas y bigramas\n",
        "            min_df=2,  # Aparecer al menos en 2 documentos\n",
        "            max_df=0.95  # No más del 95% de documentos\n",
        "        )\n",
        "\n",
        "        # Ajustar y transformar\n",
        "        tfidf_matrix = tfidf.fit_transform(textos)\n",
        "\n",
        "        # Crear columnas de características\n",
        "        feature_names = [f\"{col}_tfidf_{i}\" for i in range(tfidf_matrix.shape[1])]\n",
        "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names, index=df.index)\n",
        "\n",
        "        # Agregar al dataframe\n",
        "        df_resultado = pd.concat([df_resultado, tfidf_df], axis=1)\n",
        "\n",
        "        # Eliminar columna original\n",
        "        df_resultado = df_resultado.drop(columns=[col])\n",
        "\n",
        "        # Guardar mapeo\n",
        "        mapeos_texto[col] = {\n",
        "            'vectorizer': tfidf,\n",
        "            'feature_names': feature_names,\n",
        "            'vocabulary': tfidf.vocabulary_\n",
        "        }\n",
        "\n",
        "        print(f\"  {col}: {len(feature_names)} características TF-IDF generadas\")\n",
        "        print(f\"    Vocabulario: {len(tfidf.vocabulary_)} términos únicos\")\n",
        "\n",
        "    return df_resultado, mapeos_texto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bloque ejecuta todas las conversiones de tipos de datos que definimos en las funciones pasadas, por lo tanto tarda 1-2 minutos"
      ],
      "metadata": {
        "id": "Cs5aVA4cAFx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_-9g8xQ2jv1",
        "outputId": "d39c9123-b161-4cb0-c2be-d242bfa5c84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== APLICANDO CONVERSIONES ===\n",
            "\n",
            "--- Convirtiendo columnas binarias (Si/No y S/N) ---\n",
            "Columna: FAMI_TIENEINTERNET\n",
            "  Valores únicos: ['Si' 'No']\n",
            "  → Mapeo aplicado: {'No': 0, 'Si': 1}\n",
            "Columna: FAMI_TIENELAVADORA\n",
            "  Valores únicos: ['Si' 'No']\n",
            "  → Mapeo aplicado: {'No': 0, 'Si': 1}\n",
            "Columna: FAMI_TIENEAUTOMOVIL\n",
            "  Valores únicos: ['Si' 'No']\n",
            "  → Mapeo aplicado: {'No': 0, 'Si': 1}\n",
            "Columna: ESTU_PRIVADO_LIBERTAD\n",
            "  Valores únicos: ['N' 'S']\n",
            "  → Mapeo aplicado: {'N': 0, 'S': 1}\n",
            "Columna: ESTU_PAGOMATRICULAPROPIO\n",
            "  Valores únicos: ['No' 'Si']\n",
            "  → Mapeo aplicado: {'No': 0, 'Si': 1}\n",
            "Columna: FAMI_TIENECOMPUTADOR\n",
            "  Valores únicos: ['Si' 'No']\n",
            "  → Mapeo aplicado: {'No': 0, 'Si': 1}\n",
            "Columna: FAMI_TIENEINTERNET.1\n",
            "  Valores únicos: ['Si' 'No']\n",
            "  → Mapeo aplicado: {'No': 0, 'Si': 1}\n",
            "\n",
            "--- Convirtiendo columnas ordinales ---\n",
            "  ADVERTENCIA: FAMI_ESTRATOVIVIENDA no tiene orden predefinido, usando alfabético: ['Estrato 1', 'Estrato 2', 'Estrato 3', 'Estrato 4', 'Estrato 5', 'Estrato 6', 'Sin Estrato']\n",
            "  FAMI_ESTRATOVIVIENDA: {'Estrato 1': 0, 'Estrato 2': 1, 'Estrato 3': 2, 'Estrato 4': 3, 'Estrato 5': 4, 'Estrato 6': 5, 'Sin Estrato': 6}\n",
            "  ADVERTENCIA: FAMI_EDUCACIONPADRE no tiene orden predefinido, usando alfabético: ['Educación profesional completa', 'Educación profesional incompleta', 'Ninguno', 'No Aplica', 'No sabe', 'Postgrado', 'Primaria completa', 'Primaria incompleta', 'Secundaria (Bachillerato) completa', 'Secundaria (Bachillerato) incompleta', 'Técnica o tecnológica completa', 'Técnica o tecnológica incompleta']\n",
            "  FAMI_EDUCACIONPADRE: {'Educación profesional completa': 0, 'Educación profesional incompleta': 1, 'Ninguno': 2, 'No Aplica': 3, 'No sabe': 4, 'Postgrado': 5, 'Primaria completa': 6, 'Primaria incompleta': 7, 'Secundaria (Bachillerato) completa': 8, 'Secundaria (Bachillerato) incompleta': 9, 'Técnica o tecnológica completa': 10, 'Técnica o tecnológica incompleta': 11}\n",
            "  ADVERTENCIA: FAMI_EDUCACIONMADRE no tiene orden predefinido, usando alfabético: ['Educación profesional completa', 'Educación profesional incompleta', 'Ninguno', 'No Aplica', 'No sabe', 'Postgrado', 'Primaria completa', 'Primaria incompleta', 'Secundaria (Bachillerato) completa', 'Secundaria (Bachillerato) incompleta', 'Técnica o tecnológica completa', 'Técnica o tecnológica incompleta']\n",
            "  FAMI_EDUCACIONMADRE: {'Educación profesional completa': 0, 'Educación profesional incompleta': 1, 'Ninguno': 2, 'No Aplica': 3, 'No sabe': 4, 'Postgrado': 5, 'Primaria completa': 6, 'Primaria incompleta': 7, 'Secundaria (Bachillerato) completa': 8, 'Secundaria (Bachillerato) incompleta': 9, 'Técnica o tecnológica completa': 10, 'Técnica o tecnológica incompleta': 11}\n",
            "\n",
            "--- Convirtiendo variable objetivo: RENDIMIENTO_GLOBAL ---\n",
            "\n",
            "--- Convirtiendo columnas ordinales ---\n",
            "  RENDIMIENTO_GLOBAL: {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
            "\n",
            "--- Convirtiendo columnas nominales (OneHot) ---\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD: 9 columnas generadas\n",
            "    ['ESTU_VALORMATRICULAUNIVERSIDAD_Entre 1 millón y menos de 2.5 millones', 'ESTU_VALORMATRICULAUNIVERSIDAD_Entre 2.5 millones y menos de 4 millones', 'ESTU_VALORMATRICULAUNIVERSIDAD_Entre 4 millones y menos de 5.5 millones']...\n",
            "  ESTU_HORASSEMANATRABAJA: 6 columnas generadas\n",
            "    ['ESTU_HORASSEMANATRABAJA_0', 'ESTU_HORASSEMANATRABAJA_Entre 11 y 20 horas', 'ESTU_HORASSEMANATRABAJA_Entre 21 y 30 horas']...\n",
            "\n",
            "--- Convirtiendo columnas nominales (Label) ---\n",
            "  ESTU_PRGM_DEPARTAMENTO: 31 categorías únicas\n",
            "    Muestra: {'AMAZONAS': np.int64(0), 'ANTIOQUIA': np.int64(1), 'ARAUCA': np.int64(2)}\n",
            "\n",
            "--- Convirtiendo columnas de texto (TF-IDF) ---\n",
            "  ESTU_PRGM_ACADEMICO: 30 características TF-IDF generadas\n",
            "    Vocabulario: 30 términos únicos\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# APLICAR TODAS LAS CONVERSIONES\n",
        "# ===================================================================\n",
        "\n",
        "print(f\"\\n=== APLICANDO CONVERSIONES ===\")\n",
        "\n",
        "# Crear copia para trabajar\n",
        "df_numerico = df.copy()\n",
        "todos_los_mapeos = {}\n",
        "\n",
        "# 1. Convertir columnas binarias\n",
        "if tipos_conversion['binarias']:\n",
        "    df_numerico, mapeos_bin = convertir_binarias(df_numerico, tipos_conversion['binarias'])\n",
        "    todos_los_mapeos['binarias'] = mapeos_bin\n",
        "\n",
        "# 2. Convertir columnas ordinales\n",
        "if tipos_conversion['ordinales']:\n",
        "    df_numerico, mapeos_ord = convertir_ordinales(df_numerico, tipos_conversion['ordinales'])\n",
        "    todos_los_mapeos['ordinales'] = mapeos_ord\n",
        "\n",
        "# 3. Convertir variable objetivo si no es numérica\n",
        "target_col = 'RENDIMIENTO_GLOBAL'\n",
        "if target_col in df_numerico.columns and not pd.api.types.is_numeric_dtype(df_numerico[target_col]):\n",
        "    print(f\"\\n--- Convirtiendo variable objetivo: {target_col} ---\")\n",
        "    df_numerico, mapeo_target = convertir_ordinales(df_numerico, [target_col])\n",
        "    todos_los_mapeos['target'] = mapeo_target\n",
        "\n",
        "# 4. Convertir nominales con OneHot (pocas categorías)\n",
        "if tipos_conversion['nominales_pocas']:\n",
        "    df_numerico, mapeos_onehot = convertir_nominales_onehot(df_numerico, tipos_conversion['nominales_pocas'])\n",
        "    todos_los_mapeos['onehot'] = mapeos_onehot\n",
        "\n",
        "# 5. Convertir nominales con Label encoding (muchas categorías)\n",
        "if tipos_conversion['nominales_muchas']:\n",
        "    df_numerico, mapeos_label = convertir_nominales_label(df_numerico, tipos_conversion['nominales_muchas'])\n",
        "    todos_los_mapeos['label'] = mapeos_label\n",
        "\n",
        "# 6. Convertir texto con TF-IDF\n",
        "if tipos_conversion['texto']:\n",
        "    df_numerico, mapeos_tfidf = convertir_texto_tfidf(df_numerico, tipos_conversion['texto'], max_features=30)\n",
        "    todos_los_mapeos['tfidf'] = mapeos_tfidf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF2fZAet2kSV",
        "outputId": "5888afd6-735d-4623-eb41-e65f332357df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== VERIFICACIÓN FINAL ===\n",
            "Dataset original: (692500, 21)\n",
            "Dataset numérico final: (692500, 62)\n",
            "\n",
            "Tipos de datos finales:\n",
            "float64    43\n",
            "bool       15\n",
            "int64       4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "⚠️  ADVERTENCIA: Columnas aún no numéricas:\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_Entre 1 millón y menos de 2.5 millones: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_Entre 2.5 millones y menos de 4 millones: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_Entre 4 millones y menos de 5.5 millones: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_Entre 5.5 millones y menos de 7 millones: bool - Valores únicos: 2\n",
            "    Muestra: [ True False]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_Entre 500 mil y menos de 1 millón: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_Menos de 500 mil: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_Más de 7 millones: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_No pagó matrícula: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_VALORMATRICULAUNIVERSIDAD_nan: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_HORASSEMANATRABAJA_0: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_HORASSEMANATRABAJA_Entre 11 y 20 horas: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_HORASSEMANATRABAJA_Entre 21 y 30 horas: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_HORASSEMANATRABAJA_Menos de 10 horas: bool - Valores únicos: 2\n",
            "    Muestra: [ True False]\n",
            "  ESTU_HORASSEMANATRABAJA_Más de 30 horas: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "  ESTU_HORASSEMANATRABAJA_nan: bool - Valores únicos: 2\n",
            "    Muestra: [False  True]\n",
            "\n",
            "Valores faltantes por columna:\n",
            "FAMI_ESTRATOVIVIENDA        32137\n",
            "FAMI_TIENEINTERNET          26629\n",
            "FAMI_EDUCACIONPADRE         23178\n",
            "FAMI_TIENELAVADORA          39773\n",
            "FAMI_TIENEAUTOMOVIL         43623\n",
            "ESTU_PAGOMATRICULAPROPIO     6498\n",
            "FAMI_TIENECOMPUTADOR        38103\n",
            "FAMI_TIENEINTERNET.1        26629\n",
            "FAMI_EDUCACIONMADRE         23664\n",
            "dtype: int64\n",
            "\n",
            "Estadísticas del dataset numérico:\n",
            "- Filas: 692500\n",
            "- Columnas: 62\n",
            "- Memoria: 258.22 MB\n",
            "\n",
            "Datos listos para modelos:\n",
            "- Características (X): (692500, 61)\n",
            "- Variable objetivo (y): (692500,)\n",
            "- Distribución de y: [172987, 172275, 171619, 175619]\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# VERIFICAR RESULTADO FINAL\n",
        "# ===================================================================\n",
        "\n",
        "print(f\"\\n=== VERIFICACIÓN FINAL ===\")\n",
        "\n",
        "# Excluir columna ID si existe\n",
        "if 'ID' in df_numerico.columns:\n",
        "    df_final = df_numerico.drop(columns=['ID'])\n",
        "else:\n",
        "    df_final = df_numerico.copy()\n",
        "\n",
        "print(f\"Dataset original: {df.shape}\")\n",
        "print(f\"Dataset numérico final: {df_final.shape}\")\n",
        "\n",
        "# Verificar que todas las columnas son numéricas\n",
        "print(f\"\\nTipos de datos finales:\")\n",
        "tipos_finales = df_final.dtypes\n",
        "print(tipos_finales.value_counts())\n",
        "\n",
        "# Identificar cualquier columna que no sea numérica\n",
        "columnas_no_numericas = df_final.select_dtypes(exclude=[np.number]).columns\n",
        "if len(columnas_no_numericas) > 0:\n",
        "    print(f\"\\n⚠️  ADVERTENCIA: Columnas aún no numéricas:\")\n",
        "    for col in columnas_no_numericas:\n",
        "        print(f\"  {col}: {df_final[col].dtype} - Valores únicos: {df_final[col].nunique()}\")\n",
        "        print(f\"    Muestra: {df_final[col].unique()[:3]}\")\n",
        "else:\n",
        "    print(f\"\\n✓ ÉXITO: Todas las columnas son numéricas\")\n",
        "\n",
        "# Verificar valores faltantes\n",
        "print(f\"\\nValores faltantes por columna:\")\n",
        "valores_faltantes = df_final.isnull().sum()\n",
        "if valores_faltantes.sum() > 0:\n",
        "    print(valores_faltantes[valores_faltantes > 0])\n",
        "else:\n",
        "    print(\"No hay valores faltantes\")\n",
        "\n",
        "# Estadísticas básicas\n",
        "print(f\"\\nEstadísticas del dataset numérico:\")\n",
        "print(f\"- Filas: {len(df_final)}\")\n",
        "print(f\"- Columnas: {len(df_final.columns)}\")\n",
        "print(f\"- Memoria: {df_final.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Separar características y variable objetivo\n",
        "if target_col in df_final.columns:\n",
        "    X_numerico = df_final.drop(columns=[target_col])\n",
        "    y_numerico = df_final[target_col]\n",
        "\n",
        "    print(f\"\\nDatos listos para modelos:\")\n",
        "    print(f\"- Características (X): {X_numerico.shape}\")\n",
        "    print(f\"- Variable objetivo (y): {y_numerico.shape}\")\n",
        "    print(f\"- Distribución de y: {pd.Series(y_numerico).value_counts().sort_index().tolist()}\")\n",
        "else:\n",
        "    X_numerico = df_final\n",
        "    y_numerico = None\n",
        "    print(f\"\\nCaracterísticas (X): {X_numerico.shape}\")\n",
        "    print(\"No se encontró variable objetivo definida\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luCmyGKI2xpX",
        "outputId": "a70fe9ab-71aa-4dc1-a81c-f6e609f41cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== GUARDANDO RESULTADOS ===\n",
            "Dataset numérico creado y listo para modelos de ML\n",
            "Variables disponibles:\n",
            "- df_final: Dataset completo numérico\n",
            "- X_numerico: Características numéricas\n",
            "- y_numerico: Variable objetivo numérica\n",
            "- todos_los_mapeos: Mapeos para aplicar a datos nuevos\n",
            "- aplicar_conversion_datos_nuevos(): Función para datos nuevos\n",
            "\n",
            "Primeras 5 filas del dataset numérico:\n",
            "   PERIODO  ESTU_PRGM_DEPARTAMENTO  FAMI_ESTRATOVIVIENDA  FAMI_TIENEINTERNET  \\\n",
            "0    20212                       4                   2.0                 1.0   \n",
            "1    20212                       3                   2.0                 0.0   \n",
            "2    20203                       4                   2.0                 1.0   \n",
            "3    20195                      26                   3.0                 1.0   \n",
            "4    20212                       1                   2.0                 1.0   \n",
            "\n",
            "   FAMI_EDUCACIONPADRE  FAMI_TIENELAVADORA  FAMI_TIENEAUTOMOVIL  \\\n",
            "0                 11.0                 1.0                  1.0   \n",
            "1                 10.0                 1.0                  0.0   \n",
            "2                  8.0                 1.0                  0.0   \n",
            "3                  4.0                 1.0                  0.0   \n",
            "4                  6.0                 1.0                  1.0   \n",
            "\n",
            "   ESTU_PRIVADO_LIBERTAD  ESTU_PAGOMATRICULAPROPIO  FAMI_TIENECOMPUTADOR  ...  \\\n",
            "0                      0                       0.0                   1.0  ...   \n",
            "1                      0                       0.0                   1.0  ...   \n",
            "2                      0                       0.0                   0.0  ...   \n",
            "3                      0                       0.0                   1.0  ...   \n",
            "4                      0                       0.0                   1.0  ...   \n",
            "\n",
            "   ESTU_PRGM_ACADEMICO_tfidf_20  ESTU_PRGM_ACADEMICO_tfidf_21  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           0.0   \n",
            "\n",
            "   ESTU_PRGM_ACADEMICO_tfidf_22  ESTU_PRGM_ACADEMICO_tfidf_23  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           0.0   \n",
            "\n",
            "   ESTU_PRGM_ACADEMICO_tfidf_24  ESTU_PRGM_ACADEMICO_tfidf_25  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           1.0   \n",
            "\n",
            "   ESTU_PRGM_ACADEMICO_tfidf_26  ESTU_PRGM_ACADEMICO_tfidf_27  \\\n",
            "0                           0.0                           0.0   \n",
            "1                           0.0                           0.0   \n",
            "2                           0.0                           0.0   \n",
            "3                           0.0                           0.0   \n",
            "4                           0.0                           0.0   \n",
            "\n",
            "   ESTU_PRGM_ACADEMICO_tfidf_28  ESTU_PRGM_ACADEMICO_tfidf_29  \n",
            "0                           0.0                           0.0  \n",
            "1                           0.0                           0.0  \n",
            "2                           0.0                           0.0  \n",
            "3                           0.0                           0.0  \n",
            "4                           0.0                           0.0  \n",
            "\n",
            "[5 rows x 62 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"\\n=== GUARDANDO RESULTADOS ===\")\n",
        "\n",
        "# Guardar dataset numérico\n",
        "print(\"Dataset numérico creado y listo para modelos de ML\")\n",
        "print(\"Variables disponibles:\")\n",
        "print(\"- df_final: Dataset completo numérico\")\n",
        "print(\"- X_numerico: Características numéricas\")\n",
        "print(\"- y_numerico: Variable objetivo numérica\")\n",
        "print(\"- todos_los_mapeos: Mapeos para aplicar a datos nuevos\")\n",
        "print(\"- aplicar_conversion_datos_nuevos(): Función para datos nuevos\")\n",
        "\n",
        "# Mostrar muestra del resultado\n",
        "print(f\"\\nPrimeras 5 filas del dataset numérico:\")\n",
        "print(df_final.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC_1SW3gZMgw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68aRCGw-kZrW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n=== VISUALIZACIÓN DE DISTRIBUCIÓN DE COLUMNAS CON SEABORN ===\")\n",
        "\n",
        "# Seleccionar un subconjunto de columnas para visualizar para no saturar\n",
        "# Puedes ajustar este número según la cantidad total de columnas\n",
        "cols_to_visualize = df_final.columns.tolist()\n",
        "\n",
        "# Excluir columnas de texto libre normalizado si no fueron agrupadas, ya que HashingVectorizer las manejará\n",
        "cols_to_visualize = [col for col in cols_to_visualize if not (col.endswith('_normalizado') and col not in nominal_cols)]\n",
        "cols_to_visualize = [col for col in cols_to_visualize if col != TARGET_COL] # Excluir la columna original si ya creamos una limpia/final\n",
        "\n",
        "print(f\"Visualizando la distribución de {len(cols_to_visualize)} columnas...\")\n",
        "\n",
        "# Definir un número de columnas por fila para los subplots\n",
        "n_cols_subplot = 3\n",
        "n_rows_subplot = (len(cols_to_visualize) + n_cols_subplot - 1) // n_cols_subplot\n",
        "\n",
        "# Ajustar el tamaño de la figura\n",
        "plt.figure(figsize=(n_cols_subplot * 5, n_rows_subplot * 4))\n",
        "\n",
        "for i, col in enumerate(cols_to_visualize):\n",
        "    plt.subplot(n_rows_subplot, n_cols_subplot, i + 1)\n",
        "\n",
        "    # Usar seaborn para visualizar la distribución\n",
        "    if pd.api.types.is_numeric_dtype(df_final[col]):\n",
        "        # Histograma para columnas numéricas\n",
        "        sns.histplot(data=df_final, x=col, kde=True, bins=30)\n",
        "        plt.title(f'Distribución de {col} (Numérica)')\n",
        "    else:\n",
        "        # Conteo de barras para columnas categóricas\n",
        "        # Limitar a los top 10-15 valores para columnas con alta cardinalidad agrupada\n",
        "        if df_final[col].nunique() > 15:\n",
        "            top_values = df_final[col].value_counts().nlargest(15).index\n",
        "            sns.countplot(data=df_final[df_final[col].isin(top_values)], y=col, order=top_values)\n",
        "            plt.title(f'Top 15 Distribución de {col}')\n",
        "        else:\n",
        "            sns.countplot(data=df_final, y=col, order=df_final[col].value_counts().index)\n",
        "            plt.title(f'Distribución de {col}')\n",
        "        plt.ylabel('') # Eliminar la etiqueta del eje y para que no se solape\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== VISUALIZACIÓN DE DISTRIBUCIÓN COMPLETADA ===\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "11KcRjy-v0cZ",
        "outputId": "8cdeb8d8-733d-4d05-84cc-50b8b541dec6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PERIODO  ESTU_PRGM_DEPARTAMENTO  FAMI_ESTRATOVIVIENDA  FAMI_TIENEINTERNET  \\\n",
              "0    20212                       4                   2.0                 1.0   \n",
              "1    20212                       3                   2.0                 0.0   \n",
              "2    20203                       4                   2.0                 1.0   \n",
              "3    20195                      26                   3.0                 1.0   \n",
              "4    20212                       1                   2.0                 1.0   \n",
              "\n",
              "   FAMI_EDUCACIONPADRE  FAMI_TIENELAVADORA  FAMI_TIENEAUTOMOVIL  \\\n",
              "0                 11.0                 1.0                  1.0   \n",
              "1                 10.0                 1.0                  0.0   \n",
              "2                  8.0                 1.0                  0.0   \n",
              "3                  4.0                 1.0                  0.0   \n",
              "4                  6.0                 1.0                  1.0   \n",
              "\n",
              "   ESTU_PRIVADO_LIBERTAD  ESTU_PAGOMATRICULAPROPIO  FAMI_TIENECOMPUTADOR  \\\n",
              "0                      0                       0.0                   1.0   \n",
              "1                      0                       0.0                   1.0   \n",
              "2                      0                       0.0                   0.0   \n",
              "3                      0                       0.0                   1.0   \n",
              "4                      0                       0.0                   1.0   \n",
              "\n",
              "   FAMI_TIENEINTERNET.1  FAMI_EDUCACIONMADRE  RENDIMIENTO_GLOBAL  coef_1  \\\n",
              "0                   1.0                  5.0                   2   0.322   \n",
              "1                   0.0                 11.0                   0   0.311   \n",
              "2                   1.0                  8.0                   0   0.297   \n",
              "3                   1.0                  8.0                   3   0.485   \n",
              "4                   1.0                  6.0                   1   0.316   \n",
              "\n",
              "   coef_2  coef_3  coef_4  \\\n",
              "0   0.208   0.310   0.267   \n",
              "1   0.215   0.292   0.264   \n",
              "2   0.214   0.305   0.264   \n",
              "3   0.172   0.252   0.190   \n",
              "4   0.232   0.285   0.294   \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_Entre 1 millón y menos de 2.5 millones  \\\n",
              "0                                              False                       \n",
              "1                                              False                       \n",
              "2                                              False                       \n",
              "3                                              False                       \n",
              "4                                              False                       \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_Entre 2.5 millones y menos de 4 millones  \\\n",
              "0                                              False                         \n",
              "1                                               True                         \n",
              "2                                               True                         \n",
              "3                                              False                         \n",
              "4                                               True                         \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_Entre 4 millones y menos de 5.5 millones  \\\n",
              "0                                              False                         \n",
              "1                                              False                         \n",
              "2                                              False                         \n",
              "3                                               True                         \n",
              "4                                              False                         \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_Entre 5.5 millones y menos de 7 millones  \\\n",
              "0                                               True                         \n",
              "1                                              False                         \n",
              "2                                              False                         \n",
              "3                                              False                         \n",
              "4                                              False                         \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_Entre 500 mil y menos de 1 millón  \\\n",
              "0                                              False                  \n",
              "1                                              False                  \n",
              "2                                              False                  \n",
              "3                                              False                  \n",
              "4                                              False                  \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_Menos de 500 mil  \\\n",
              "0                                            False   \n",
              "1                                            False   \n",
              "2                                            False   \n",
              "3                                            False   \n",
              "4                                            False   \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_Más de 7 millones  \\\n",
              "0                                             False   \n",
              "1                                             False   \n",
              "2                                             False   \n",
              "3                                             False   \n",
              "4                                             False   \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_No pagó matrícula  \\\n",
              "0                                             False   \n",
              "1                                             False   \n",
              "2                                             False   \n",
              "3                                             False   \n",
              "4                                             False   \n",
              "\n",
              "   ESTU_VALORMATRICULAUNIVERSIDAD_nan  ESTU_HORASSEMANATRABAJA_0  \\\n",
              "0                               False                      False   \n",
              "1                               False                       True   \n",
              "2                               False                      False   \n",
              "3                               False                       True   \n",
              "4                               False                      False   \n",
              "\n",
              "   ESTU_HORASSEMANATRABAJA_Entre 11 y 20 horas  \\\n",
              "0                                        False   \n",
              "1                                        False   \n",
              "2                                        False   \n",
              "3                                        False   \n",
              "4                                        False   \n",
              "\n",
              "   ESTU_HORASSEMANATRABAJA_Entre 21 y 30 horas  \\\n",
              "0                                        False   \n",
              "1                                        False   \n",
              "2                                        False   \n",
              "3                                        False   \n",
              "4                                         True   \n",
              "\n",
              "   ESTU_HORASSEMANATRABAJA_Menos de 10 horas  \\\n",
              "0                                       True   \n",
              "1                                      False   \n",
              "2                                      False   \n",
              "3                                      False   \n",
              "4                                      False   \n",
              "\n",
              "   ESTU_HORASSEMANATRABAJA_Más de 30 horas  ESTU_HORASSEMANATRABAJA_nan  \\\n",
              "0                                    False                        False   \n",
              "1                                    False                        False   \n",
              "2                                     True                        False   \n",
              "3                                    False                        False   \n",
              "4                                    False                        False   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_0  ESTU_PRGM_ACADEMICO_tfidf_1  \\\n",
              "0                     0.000000                     0.000000   \n",
              "1                     0.000000                     0.000000   \n",
              "2                     0.000000                     0.000000   \n",
              "3                     0.451349                     0.489406   \n",
              "4                     0.000000                     0.000000   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_2  ESTU_PRGM_ACADEMICO_tfidf_3  \\\n",
              "0                          0.0                          0.0   \n",
              "1                          0.0                          0.0   \n",
              "2                          0.0                          0.0   \n",
              "3                          0.0                          0.0   \n",
              "4                          0.0                          0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_4  ESTU_PRGM_ACADEMICO_tfidf_5  \\\n",
              "0                          0.0                          0.0   \n",
              "1                          0.0                          0.0   \n",
              "2                          0.0                          0.0   \n",
              "3                          0.0                          0.0   \n",
              "4                          0.0                          0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_6  ESTU_PRGM_ACADEMICO_tfidf_7  \\\n",
              "0                          0.0                     0.000000   \n",
              "1                          0.0                     0.000000   \n",
              "2                          0.0                     0.000000   \n",
              "3                          0.0                     0.383902   \n",
              "4                          0.0                     0.000000   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_8  ESTU_PRGM_ACADEMICO_tfidf_9  \\\n",
              "0                     0.000000                          0.0   \n",
              "1                     0.000000                          0.0   \n",
              "2                     0.000000                          0.0   \n",
              "3                     0.452438                          0.0   \n",
              "4                     0.000000                          0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_10  ESTU_PRGM_ACADEMICO_tfidf_11  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           1.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_12  ESTU_PRGM_ACADEMICO_tfidf_13  \\\n",
              "0                      0.000000                           0.0   \n",
              "1                      0.000000                           0.0   \n",
              "2                      0.000000                           0.0   \n",
              "3                      0.452421                           0.0   \n",
              "4                      0.000000                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_14  ESTU_PRGM_ACADEMICO_tfidf_15  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_16  ESTU_PRGM_ACADEMICO_tfidf_17  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_18  ESTU_PRGM_ACADEMICO_tfidf_19  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_20  ESTU_PRGM_ACADEMICO_tfidf_21  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_22  ESTU_PRGM_ACADEMICO_tfidf_23  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_24  ESTU_PRGM_ACADEMICO_tfidf_25  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           1.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_26  ESTU_PRGM_ACADEMICO_tfidf_27  \\\n",
              "0                           0.0                           0.0   \n",
              "1                           0.0                           0.0   \n",
              "2                           0.0                           0.0   \n",
              "3                           0.0                           0.0   \n",
              "4                           0.0                           0.0   \n",
              "\n",
              "   ESTU_PRGM_ACADEMICO_tfidf_28  ESTU_PRGM_ACADEMICO_tfidf_29  \n",
              "0                           0.0                           0.0  \n",
              "1                           0.0                           0.0  \n",
              "2                           0.0                           0.0  \n",
              "3                           0.0                           0.0  \n",
              "4                           0.0                           0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ceae78f-84b9-40c5-af4b-7f37ce6ca143\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PERIODO</th>\n",
              "      <th>ESTU_PRGM_DEPARTAMENTO</th>\n",
              "      <th>FAMI_ESTRATOVIVIENDA</th>\n",
              "      <th>FAMI_TIENEINTERNET</th>\n",
              "      <th>FAMI_EDUCACIONPADRE</th>\n",
              "      <th>FAMI_TIENELAVADORA</th>\n",
              "      <th>FAMI_TIENEAUTOMOVIL</th>\n",
              "      <th>ESTU_PRIVADO_LIBERTAD</th>\n",
              "      <th>ESTU_PAGOMATRICULAPROPIO</th>\n",
              "      <th>FAMI_TIENECOMPUTADOR</th>\n",
              "      <th>FAMI_TIENEINTERNET.1</th>\n",
              "      <th>FAMI_EDUCACIONMADRE</th>\n",
              "      <th>RENDIMIENTO_GLOBAL</th>\n",
              "      <th>coef_1</th>\n",
              "      <th>coef_2</th>\n",
              "      <th>coef_3</th>\n",
              "      <th>coef_4</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_Entre 1 millón y menos de 2.5 millones</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_Entre 2.5 millones y menos de 4 millones</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_Entre 4 millones y menos de 5.5 millones</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_Entre 5.5 millones y menos de 7 millones</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_Entre 500 mil y menos de 1 millón</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_Menos de 500 mil</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_Más de 7 millones</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_No pagó matrícula</th>\n",
              "      <th>ESTU_VALORMATRICULAUNIVERSIDAD_nan</th>\n",
              "      <th>ESTU_HORASSEMANATRABAJA_0</th>\n",
              "      <th>ESTU_HORASSEMANATRABAJA_Entre 11 y 20 horas</th>\n",
              "      <th>ESTU_HORASSEMANATRABAJA_Entre 21 y 30 horas</th>\n",
              "      <th>ESTU_HORASSEMANATRABAJA_Menos de 10 horas</th>\n",
              "      <th>ESTU_HORASSEMANATRABAJA_Más de 30 horas</th>\n",
              "      <th>ESTU_HORASSEMANATRABAJA_nan</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_0</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_1</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_2</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_3</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_4</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_5</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_6</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_7</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_8</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_9</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_10</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_11</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_12</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_13</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_14</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_15</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_16</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_17</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_18</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_19</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_20</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_21</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_22</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_23</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_24</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_25</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_26</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_27</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_28</th>\n",
              "      <th>ESTU_PRGM_ACADEMICO_tfidf_29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20212</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.267</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20212</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.311</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.292</td>\n",
              "      <td>0.264</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20203</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.214</td>\n",
              "      <td>0.305</td>\n",
              "      <td>0.264</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20195</td>\n",
              "      <td>26</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.172</td>\n",
              "      <td>0.252</td>\n",
              "      <td>0.190</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.451349</td>\n",
              "      <td>0.489406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.383902</td>\n",
              "      <td>0.452438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.452421</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20212</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.316</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.285</td>\n",
              "      <td>0.294</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ceae78f-84b9-40c5-af4b-7f37ce6ca143')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ceae78f-84b9-40c5-af4b-7f37ce6ca143 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ceae78f-84b9-40c5-af4b-7f37ce6ca143');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e26f9594-4f8c-44be-84b2-adf8096ada90\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e26f9594-4f8c-44be-84b2-adf8096ada90')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e26f9594-4f8c-44be-84b2-adf8096ada90 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos dimos cuenta que aún quedan valores por rellenas, en este caso optamos por crear una función que los rellene de manera aleatoria"
      ],
      "metadata": {
        "id": "IlWAUa-6IcVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imputar_valores_aleatorios(df):\n",
        "    df_imputado = df.copy()\n",
        "\n",
        "    for columna in df.columns:\n",
        "        if df[columna].isnull().any():\n",
        "            valores_validos = df[columna].dropna().values\n",
        "            if len(valores_validos) > 0:\n",
        "                valores_imputados = np.random.choice(valores_validos, size=df[columna].isnull().sum(), replace=True)\n",
        "                df_imputado.loc[df[columna].isnull(), columna] = valores_imputados\n",
        "            else:\n",
        "                print(f\"La columna '{columna}' no tiene valores válidos para imputar.\")\n",
        "\n",
        "    return df_imputado"
      ],
      "metadata": {
        "id": "-StIeXsDIeEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar las columnas con datos faltantes (basado en tu output)\n",
        "missing_cols_list = [\n",
        "    'FAMI_ESTRATOVIVIENDA',\n",
        "    'FAMI_TIENEINTERNET',\n",
        "    'FAMI_EDUCACIONPADRE',\n",
        "    'FAMI_TIENELAVADORA',\n",
        "    'FAMI_TIENEAUTOMOVIL',\n",
        "    'ESTU_PAGOMATRICULAPROPIO',\n",
        "    'FAMI_TIENECOMPUTADOR',\n",
        "    'FAMI_TIENEINTERNET.1',\n",
        "    'FAMI_EDUCACIONMADRE'\n",
        "]\n",
        "\n",
        "# Asegurarse de que solo intentamos rellenar columnas que existen en df_final\n",
        "missing_cols_in_df_final = [col for col in missing_cols_list if col in df_final.columns]\n",
        "\n",
        "# Aplicar la función al dataset final numérico\n",
        "df_final_filled = imputar_valores_aleatorios(df_final)\n",
        "\n",
        "# Verificar si todavía hay valores faltantes\n",
        "print(\"\\nVerificando valores faltantes después de rellenar:\")\n",
        "valores_faltantes_after = df_final_filled.isnull().sum()\n",
        "if valores_faltantes_after.sum() > 0:\n",
        "    print(valores_faltantes_after[valores_faltantes_after > 0])\n",
        "else:\n",
        "    print(\"✓ No hay valores faltantes después del rellenado aleatorio.\")\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame con datos rellenados\n",
        "print(\"\\nPrimeras 5 filas del dataset después de rellenar:\")\n",
        "print(df_final_filled.head())"
      ],
      "metadata": {
        "id": "Mer80V8XIg0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "class Preprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, config=None, max_features_text=50, auto_detect=False):\n",
        "        \"\"\"\n",
        "        config: optional dict with keys 'binary', 'ordinal', 'onehot', 'label', 'text'\n",
        "        auto_detect: if True, detects column types automatically in fit\n",
        "        \"\"\"\n",
        "        self.config = config or {'binary': [], 'ordinal': {}, 'onehot': [], 'label': [], 'text': []}\n",
        "        self.auto_detect = auto_detect\n",
        "        self.max_features_text = max_features_text\n",
        "        self.mappings_ = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        # Auto-detect config if enabled\n",
        "        if self.auto_detect:\n",
        "            binary, onehot, label, text = [], [], [], []\n",
        "            for col in df.columns:\n",
        "                vals = df[col].dropna().unique()\n",
        "                n_unique = len(vals)\n",
        "                dtype = df[col].dtype\n",
        "                # Binary detection\n",
        "                if set(vals).issubset({'Si','No','S','N'}) and n_unique == 2:\n",
        "                    binary.append(col)\n",
        "                # Text detection\n",
        "                elif dtype == object and n_unique > self.max_features_text:\n",
        "                    text.append(col)\n",
        "                # Categorical small -> OneHot\n",
        "                elif dtype == object and n_unique <= 10:\n",
        "                    onehot.append(col)\n",
        "                # Categorical medium -> Label\n",
        "                elif dtype == object:\n",
        "                    label.append(col)\n",
        "            self.config = {'binary': binary, 'ordinal': {}, 'onehot': onehot, 'label': label, 'text': text}\n",
        "\n",
        "        # Fit binary mappings\n",
        "        self.mappings_['binary'] = {}\n",
        "        for col in self.config.get('binary', []):\n",
        "            vals = df[col].dropna().unique()\n",
        "            self.mappings_['binary'][col] = {'Si': 1, 'No': 0} if 'Si' in vals else {'S': 1, 'N': 0}\n",
        "\n",
        "        # Fit ordinal (only for explicitly provided)\n",
        "        self.mappings_['ordinal'] = {}\n",
        "        for col, order in self.config.get('ordinal', {}).items():\n",
        "            mapping = {v: i for i, v in enumerate(order)} if order else \\\n",
        "                      {v: i for i, v in enumerate(sorted(df[col].dropna().unique()))}\n",
        "            self.mappings_['ordinal'][col] = mapping\n",
        "\n",
        "        # Fit OneHot\n",
        "        self.ohe_ = {}\n",
        "        for col in self.config.get('onehot', []):\n",
        "            ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "            ohe.fit(df[[col]].astype(str))\n",
        "            self.ohe_[col] = ohe\n",
        "\n",
        "        # Fit Label\n",
        "        self.le_ = {}\n",
        "        for col in self.config.get('label', []):\n",
        "            le = LabelEncoder()\n",
        "            nonnull = df[col].dropna().astype(str)\n",
        "            le.fit(nonnull)\n",
        "            self.le_[col] = le\n",
        "\n",
        "        # Fit TF-IDF\n",
        "        self.tfidf_ = {}\n",
        "        for col in self.config.get('text', []):\n",
        "            tfidf = TfidfVectorizer(max_features=self.max_features_text,\n",
        "                                     lowercase=True, ngram_range=(1,2), min_df=2, max_df=0.95)\n",
        "            tfidf.fit(df[col].fillna('').astype(str))\n",
        "            self.tfidf_[col] = tfidf\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "        # Apply binary\n",
        "        for col, m in self.mappings_.get('binary', {}).items():\n",
        "            df[col] = df[col].map(m).fillna(0).astype(int)\n",
        "        # Apply ordinal\n",
        "        for col, m in self.mappings_.get('ordinal', {}).items():\n",
        "            df[col] = df[col].map(m).fillna(-1).astype(int)\n",
        "        # Apply OneHot\n",
        "        for col, ohe in self.ohe_.items():\n",
        "            arr = ohe.transform(df[[col]].astype(str))\n",
        "            cols = [f\"{col}_oh_{cat}\" for cat in ohe.categories_[0]]\n",
        "            df_oh = pd.DataFrame(arr, columns=cols, index=df.index)\n",
        "            df = pd.concat([df, df_oh], axis=1)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "        # Apply Label\n",
        "        for col, le in self.le_.items():\n",
        "            df[col] = df[col].fillna('').apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
        "        # Apply TF-IDF\n",
        "        for col, tfidf in self.tfidf_.items():\n",
        "            arr = tfidf.transform(df[col].fillna('').astype(str)).toarray()\n",
        "            cols = [f\"{col}_tfidf_{i}\" for i in range(arr.shape[1])]\n",
        "            df_t = pd.DataFrame(arr, columns=cols, index=df.index)\n",
        "            df = pd.concat([df, df_t], axis=1)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "        # Random imputation\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().any():\n",
        "                vals = df[col].dropna().values\n",
        "                df.loc[df[col].isnull(), col] = np.random.choice(vals, size=df[col].isnull().sum())\n",
        "        return df\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"Loaded {path} with shape {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def full_pipeline(train_path, test_path, id_col, target_col, config=None,\n",
        "                  auto_detect=False, output_submission=None):\n",
        "    \"\"\"\n",
        "    Loads data, auto-detects or uses config, preprocesses, trains logistic regression,\n",
        "    and outputs submission DataFrame (and CSV if path provided).\n",
        "    \"\"\"\n",
        "    train = load_data(train_path)\n",
        "    test = load_data(test_path)\n",
        "\n",
        "    source_cols = [c for c in train.columns if c not in [id_col, target_col]]\n",
        "    all_data = pd.concat([train[source_cols], test[source_cols]], ignore_index=True)\n",
        "\n",
        "    pre = Preprocessor(config=config, max_features_text=50, auto_detect=auto_detect)\n",
        "    pre.fit(all_data)\n",
        "    all_prep = pre.transform(all_data)\n",
        "\n",
        "    n_train = train.shape[0]\n",
        "    X_train = all_prep.iloc[:n_train].values\n",
        "    y_train = train[target_col].values\n",
        "    X_test = all_prep.iloc[n_train:].values\n",
        "\n",
        "    print(f\"Processed shapes: X_train={X_train.shape}, y_train={y_train.shape}, X_test={X_test.shape}\")\n",
        "\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds_train = model.predict(X_train)\n",
        "    print(f\"Train Accuracy: {accuracy_score(y_train, preds_train):.4f}\")\n",
        "    print(classification_report(y_train, preds_train))\n",
        "\n",
        "    preds_test = model.predict(X_test)\n",
        "    submission = pd.DataFrame({id_col: test[id_col], target_col: preds_test})\n",
        "    if output_submission:\n",
        "        submission.to_csv(output_submission, index=False)\n",
        "        print(f\"Saved submission to {output_submission}\")\n",
        "    return submission, model\n"
      ],
      "metadata": {
        "id": "Wpngz98Oy5Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission, model = full_pipeline(\n",
        "    'train.csv', 'test.csv',\n",
        "    id_col='ID', target_col='RENDIMIENTO_GLOBAL',\n",
        "    auto_detect=True,\n",
        "    output_submission='submission.csv'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5dkUZ7zxc2D",
        "outputId": "1f368401-e7f0-4fe5-d004-20f0a8a4f666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train.csv with shape (692500, 21)\n",
            "Loaded test.csv with shape (296786, 20)\n",
            "Processed shapes: X_train=(692500, 88), y_train=(692500,), X_test=(296786, 88)\n",
            "Train Accuracy: 0.3820\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        alto       0.46      0.59      0.52    175619\n",
            "        bajo       0.39      0.52      0.45    172987\n",
            "  medio-alto       0.29      0.18      0.22    171619\n",
            "  medio-bajo       0.30      0.23      0.26    172275\n",
            "\n",
            "    accuracy                           0.38    692500\n",
            "   macro avg       0.36      0.38      0.36    692500\n",
            "weighted avg       0.36      0.38      0.36    692500\n",
            "\n",
            "Saved submission to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "class Preprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, config=None, max_features_text=50, auto_detect=False):\n",
        "        \"\"\"\n",
        "        config: optional dict with keys 'binary', 'ordinal', 'onehot', 'label', 'text'\n",
        "        auto_detect: if True, detects column types automatically in fit\n",
        "        \"\"\"\n",
        "        self.config = config or {'binary': [], 'ordinal': {}, 'onehot': [], 'label': [], 'text': []}\n",
        "        self.auto_detect = auto_detect\n",
        "        self.max_features_text = max_features_text\n",
        "        self.mappings_ = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        # Auto-detect config if enabled\n",
        "        if self.auto_detect:\n",
        "            binary, onehot, label, text = [], [], [], []\n",
        "            for col in df.columns:\n",
        "                vals = df[col].dropna().unique()\n",
        "                n_unique = len(vals)\n",
        "                dtype = df[col].dtype\n",
        "                if set(vals).issubset({'Si','No','S','N'}) and n_unique == 2:\n",
        "                    binary.append(col)\n",
        "                elif dtype == object and n_unique > self.max_features_text:\n",
        "                    text.append(col)\n",
        "                elif dtype == object and n_unique <= 10:\n",
        "                    onehot.append(col)\n",
        "                elif dtype == object:\n",
        "                    label.append(col)\n",
        "            self.config = {'binary': binary, 'ordinal': {}, 'onehot': onehot, 'label': label, 'text': text}\n",
        "\n",
        "        # Fit binary mappings\n",
        "        self.mappings_['binary'] = {}\n",
        "        for col in self.config.get('binary', []):\n",
        "            vals = df[col].dropna().unique()\n",
        "            self.mappings_['binary'][col] = {'Si': 1, 'No': 0} if 'Si' in vals else {'S': 1, 'N': 0}\n",
        "\n",
        "        # Fit ordinal\n",
        "        self.mappings_['ordinal'] = {}\n",
        "        for col, order in self.config.get('ordinal', {}).items():\n",
        "            mapping = {v: i for i, v in enumerate(order)} if order else {v: i for i, v in enumerate(sorted(df[col].dropna().unique()))}\n",
        "            self.mappings_['ordinal'][col] = mapping\n",
        "\n",
        "        # Fit OneHot\n",
        "        self.ohe_ = {}\n",
        "        for col in self.config.get('onehot', []):\n",
        "            ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "            ohe.fit(df[[col]].astype(str))\n",
        "            self.ohe_[col] = ohe\n",
        "\n",
        "        # Fit Label\n",
        "        self.le_ = {}\n",
        "        for col in self.config.get('label', []):\n",
        "            le = LabelEncoder()\n",
        "            nonnull = df[col].dropna().astype(str)\n",
        "            le.fit(nonnull)\n",
        "            self.le_[col] = le\n",
        "\n",
        "        # Fit TF-IDF\n",
        "        self.tfidf_ = {}\n",
        "        for col in self.config.get('text', []):\n",
        "            tfidf = TfidfVectorizer(max_features=self.max_features_text, lowercase=True, ngram_range=(1,2), min_df=2, max_df=0.95)\n",
        "            tfidf.fit(df[col].fillna('').astype(str))\n",
        "            self.tfidf_[col] = tfidf\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "        # Apply binary\n",
        "        for col, m in self.mappings_.get('binary', {}).items():\n",
        "            df[col] = df[col].map(m).fillna(0).astype(int)\n",
        "        # Apply ordinal\n",
        "        for col, m in self.mappings_.get('ordinal', {}).items():\n",
        "            df[col] = df[col].map(m).fillna(-1).astype(int)\n",
        "        # Apply OneHot\n",
        "        for col, ohe in self.ohe_.items():\n",
        "            arr = ohe.transform(df[[col]].astype(str))\n",
        "            cols = [f\"{col}_oh_{cat}\" for cat in ohe.categories_[0]]\n",
        "            df_oh = pd.DataFrame(arr, columns=cols, index=df.index)\n",
        "            df = pd.concat([df, df_oh], axis=1)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "        # Apply Label\n",
        "        for col, le in self.le_.items():\n",
        "            df[col] = df[col].fillna('').apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
        "        # Apply TF-IDF\n",
        "        for col, tfidf in self.tfidf_.items():\n",
        "            arr = tfidf.transform(df[col].fillna('').astype(str)).toarray()\n",
        "            cols = [f\"{col}_tfidf_{i}\" for i in range(arr.shape[1])]\n",
        "            df_t = pd.DataFrame(arr, columns=cols, index=df.index)\n",
        "            df = pd.concat([df, df_t], axis=1)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "        # Random imputation\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().any():\n",
        "                vals = df[col].dropna().values\n",
        "                df.loc[df[col].isnull(), col] = np.random.choice(vals, size=df[col].isnull().sum())\n",
        "        return df\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"Loaded {path} with shape {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def full_pipeline(train_path, test_path, id_col, target_col, config=None,\n",
        "                  auto_detect=False, sample_frac=None, output_submission=None):\n",
        "    \"\"\"\n",
        "    Loads data, optionally subsamples, preprocesses, trains logistic regression,\n",
        "    and outputs submission DataFrame (and CSV if path provided).\n",
        "\n",
        "    sample_frac: float in (0,1] to subsample train and test for speed.\n",
        "    \"\"\"\n",
        "    train = load_data(train_path)\n",
        "    test = load_data(test_path)\n",
        "\n",
        "    if sample_frac is not None:\n",
        "        train = train.sample(frac=sample_frac, random_state=42).reset_index(drop=True)\n",
        "        test = test.sample(frac=sample_frac, random_state=42).reset_index(drop=True)\n",
        "        print(f\"Subsampled to fraction {sample_frac}: train {train.shape}, test {test.shape}\")\n",
        "\n",
        "    source_cols = [c for c in train.columns if c not in [id_col, target_col]]\n",
        "    all_data = pd.concat([train[source_cols], test[source_cols]], ignore_index=True)\n",
        "\n",
        "    pre = Preprocessor(config=config, max_features_text=50, auto_detect=auto_detect)\n",
        "    pre.fit(all_data)\n",
        "    all_prep = pre.transform(all_data)\n",
        "\n",
        "    n_train = train.shape[0]\n",
        "    X_train = all_prep.iloc[:n_train].values\n",
        "    y_train = train[target_col].values\n",
        "    X_test = all_prep.iloc[n_train:].values\n",
        "\n",
        "    print(f\"Processed shapes: X_train={X_train.shape}, y_train={y_train.shape}, X_test={X_test.shape}\")\n",
        "\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds_train = model.predict(X_train)\n",
        "    print(f\"Train Accuracy: {accuracy_score(y_train, preds_train):.4f}\")\n",
        "    print(classification_report(y_train, preds_train))\n",
        "\n",
        "    preds_test = model.predict(X_test)\n",
        "    submission = pd.DataFrame({id_col: test[id_col], target_col: preds_test})\n",
        "    if output_submission:\n",
        "        submission.to_csv(output_submission, index=False)\n",
        "        print(f\"Saved submission to {output_submission}\")\n",
        "    return submission, model\n"
      ],
      "metadata": {
        "id": "3qrSoG5x1Vs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission, model = full_pipeline(\n",
        "    'train.csv', 'test.csv',\n",
        "    id_col='ID', target_col='RENDIMIENTO_GLOBAL',\n",
        "    auto_detect=True,\n",
        "    sample_frac=0.1,           # usa solo el 10% de train y test\n",
        "    output_submission='submission.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "yiKdEPyg1dyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}