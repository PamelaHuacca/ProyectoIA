{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luiscontreras7/Proyecto-IA-1-/blob/main/99_Modelo_solucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V_6E9p8HDkz",
        "outputId": "d9514139-5c10-456b-a065-13b40ab1ae50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "usage: kaggle [-h] [-v] [-W]\n",
            "              {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
            "              ...\n",
            "kaggle: error: the following arguments are required: command\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "!kaggle\n",
        "!chmod 600 ./kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QIDOttuG5Pf",
        "outputId": "c5f74f6d-3f19-4d45-d916-d67a2160b9f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 1.25GB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJncLJDLItzC",
        "outputId": "154e0ce1-394f-40b0-9c0d-d2b8df1f6854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip\n",
            "  inflating: submission_example.csv  \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13vGDyTwKfML"
      },
      "source": [
        "El paradigma a seguir es supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYWLjVXWTczE",
        "outputId": "5c488286-ca7c-48d4-fb12-fdb721a15ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class Preprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, config=None, max_features_text=50, auto_detect=False):\n",
        "        self.config = config or {'binary': [], 'ordinal': {}, 'onehot': [], 'label': [], 'text': []}\n",
        "        self.auto_detect = auto_detect\n",
        "        self.max_features_text = max_features_text\n",
        "        self.mappings_ = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        if self.auto_detect:\n",
        "            binary, onehot, label, text = [], [], [], []\n",
        "            for col in df.columns:\n",
        "                vals = df[col].dropna().unique()\n",
        "                n_unique = len(vals)\n",
        "                dtype = df[col].dtype\n",
        "                if set(vals).issubset({'Si','No','S','N'}) and n_unique == 2:\n",
        "                    binary.append(col)\n",
        "                elif dtype == object and n_unique > self.max_features_text:\n",
        "                    text.append(col)\n",
        "                elif dtype == object and n_unique <= 10:\n",
        "                    onehot.append(col)\n",
        "                elif dtype == object:\n",
        "                    label.append(col)\n",
        "            self.config = {'binary': binary, 'ordinal': {}, 'onehot': onehot, 'label': label, 'text': text}\n",
        "\n",
        "        self.mappings_['binary'] = {}\n",
        "        for col in self.config['binary']:\n",
        "            vals = df[col].dropna().unique()\n",
        "            self.mappings_['binary'][col] = {'Si':1,'No':0} if 'Si' in vals else {'S':1,'N':0}\n",
        "\n",
        "        self.mappings_['ordinal'] = {}\n",
        "        for col, order in self.config.get('ordinal',{}).items():\n",
        "            mapping = {v:i for i,v in enumerate(order)} if order else {v:i for i,v in enumerate(sorted(df[col].dropna().unique()))}\n",
        "            self.mappings_['ordinal'][col] = mapping\n",
        "\n",
        "        self.ohe_ = {}\n",
        "        for col in self.config['onehot']:\n",
        "            ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "            ohe.fit(df[[col]].astype(str))\n",
        "            self.ohe_[col] = ohe\n",
        "\n",
        "        self.le_ = {}\n",
        "        for col in self.config['label']:\n",
        "            le = LabelEncoder()\n",
        "            le.fit(df[col].dropna().astype(str))\n",
        "            self.le_[col] = le\n",
        "\n",
        "        self.tfidf_ = {}\n",
        "        for col in self.config['text']:\n",
        "            tfidf = TfidfVectorizer(max_features=self.max_features_text, lowercase=True,\n",
        "                                     ngram_range=(1,2), min_df=2, max_df=0.95)\n",
        "            tfidf.fit(df[col].fillna('').astype(str))\n",
        "            self.tfidf_[col] = tfidf\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "        for col, m in self.mappings_['binary'].items():\n",
        "            df[col] = df[col].map(m).fillna(0).astype(int)\n",
        "        for col, m in self.mappings_['ordinal'].items():\n",
        "            df[col] = df[col].map(m).fillna(-1).astype(int)\n",
        "        for col, ohe in self.ohe_.items():\n",
        "            arr = ohe.transform(df[[col]].astype(str))\n",
        "            cols = [f\"{col}_oh_{cat}\" for cat in ohe.categories_[0]]\n",
        "            df_oh = pd.DataFrame(arr, columns=cols, index=df.index)\n",
        "            df = pd.concat([df, df_oh], axis=1)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "        for col, le in self.le_.items():\n",
        "            df[col] = df[col].fillna('').apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
        "        for col, tfidf in self.tfidf_.items():\n",
        "            arr = tfidf.transform(df[col].fillna('').astype(str)).toarray()\n",
        "            cols = [f\"{col}_tfidf_{i}\" for i in range(arr.shape[1])]\n",
        "            df_t = pd.DataFrame(arr, columns=cols, index=df.index)\n",
        "            df = pd.concat([df, df_t], axis=1)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "        for col in df.columns:\n",
        "            if df[col].isnull().any():\n",
        "                vals = df[col].dropna().values\n",
        "                df.loc[df[col].isnull(), col] = np.random.choice(vals, size=df[col].isnull().sum())\n",
        "        return df\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"Loaded {path} with shape {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def ensemble_pipeline(train_path, test_path, id_col, target_col,\n",
        "                      method='gb', auto_detect=False, sample_frac=None,\n",
        "                      output_submission=None):\n",
        "    \"\"\"\n",
        "    method: 'bag' (RandomForest), 'gb' (HistGradientBoosting), 'stack' (stacking RF + SVM).\n",
        "    \"\"\"\n",
        "    train = load_data(train_path)\n",
        "    test = load_data(test_path)\n",
        "\n",
        "    if sample_frac:\n",
        "        train = train.sample(frac=sample_frac, random_state=42).reset_index(drop=True)\n",
        "        test = test.sample(frac=sample_frac, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    cols = [c for c in train.columns if c not in [id_col, target_col]]\n",
        "    all_df = pd.concat([train[cols], test[cols]], ignore_index=True)\n",
        "    pre = Preprocessor(auto_detect=auto_detect)\n",
        "    pre.fit(all_df)\n",
        "    all_p = pre.transform(all_df)\n",
        "\n",
        "    n = len(train)\n",
        "    X_train, y_train = all_p.iloc[:n].values, train[target_col].values\n",
        "    X_test = all_p.iloc[n:].values\n",
        "\n",
        "    if method == 'bag':\n",
        "        # Bagging: Random Forest rápido y robusto\n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=100, max_depth=10, max_features='sqrt',\n",
        "            n_jobs=-1, random_state=42\n",
        "        )\n",
        "    elif method == 'gb':\n",
        "        # Boosting: HistGradientBoosting eficiente en grandes datos\n",
        "        model = HistGradientBoostingClassifier(\n",
        "            learning_rate=0.1, max_iter=200, max_depth=8,\n",
        "            early_stopping=True, random_state=42\n",
        "        )\n",
        "    elif method == 'stack':\n",
        "        # Stacking RF + SVM con meta-regresor ligero\n",
        "        base_estimators = [\n",
        "            ('rf', RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42)),\n",
        "            ('svm', LinearSVC(C=0.5, max_iter=2000, dual=False))\n",
        "        ]\n",
        "        model = StackingClassifier(\n",
        "            estimators=base_estimators,\n",
        "            final_estimator=LogisticRegression(max_iter=1000),\n",
        "            cv=5, n_jobs=-1\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Método no soportado: elige 'bag','gb' o 'stack'.\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"{method} train accuracy:\", accuracy_score(y_train, model.predict(X_train)))\n",
        "    print(classification_report(y_train, model.predict(X_train)))\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    submission = pd.DataFrame({id_col: test[id_col], target_col: preds})\n",
        "    if output_submission:\n",
        "        submission.to_csv(output_submission, index=False)\n",
        "        print(f\"Saved submission to {output_submission}\")\n",
        "    return submission, model\n"
      ],
      "metadata": {
        "id": "5r1TIggi6OkR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente celda tarda, aprox 15 minutos por la robustez del modelo"
      ],
      "metadata": {
        "id": "NFOtgR-adpTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_gb, gb_model = ensemble_pipeline(\n",
        "    'train.csv', 'test.csv',\n",
        "    id_col='ID', target_col='RENDIMIENTO_GLOBAL',\n",
        "    method='gb', auto_detect=True, #sample_frac=0.1,\n",
        "    output_submission='submission_gb.csv'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPAWEg3Z6UF5",
        "outputId": "a648e4bd-f2ff-4a09-e1cb-79ffb2d22272"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train.csv with shape (692500, 21)\n",
            "Loaded test.csv with shape (296786, 20)\n",
            "gb train accuracy: 0.4485415162454874\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        alto       0.54      0.64      0.59    175619\n",
            "        bajo       0.47      0.58      0.52    172987\n",
            "  medio-alto       0.35      0.28      0.31    171619\n",
            "  medio-bajo       0.36      0.29      0.32    172275\n",
            "\n",
            "    accuracy                           0.45    692500\n",
            "   macro avg       0.43      0.45      0.44    692500\n",
            "weighted avg       0.43      0.45      0.44    692500\n",
            "\n",
            "Saved submission to submission_gb.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia -f submission_gb.csv -m \"Message\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2n78fbydXIP",
        "outputId": "9963849a-7963-4fe8-f416-68b0491853d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4.03M/4.03M [00:00<00:00, 6.36MB/s]\n",
            "Successfully submitted to UDEA/ai4eng 20251 - Pruebas Saber Pro Colombia"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC_1SW3gZMgw"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}